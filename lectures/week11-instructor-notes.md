# Week 11 Lecture: Instructor Notes and Speaking Points
# 第11週講義：インストラクターノートとスピーキングポイント

**Course:** HCI-101 - Introduction to Human-Computer Interaction
**コース：** HCI-101 - ヒューマンコンピュータインタラクション入門
**Instructor:** Yuri Tijerino
**Duration:** 15-20 minutes
**Target Audience:** Undergraduate students, no programming experience required

---

## Pre-Lecture Setup | 講義前セットアップ

### Technical Preparation | 技術的準備
- [ ] Test bot portal access and assessment functionality
- [ ] Verify students have access to their prototypes
- [ ] Prepare analysis templates for distribution
- [ ] Test presentation slides on classroom display
- [ ] Have backup plan for internet connectivity issues
- [ ] Prepare examples of good vs. bad usability findings reports

### Materials to Distribute | 配布する教材
- [ ] Analysis templates (severity rating, priority matrix)
- [ ] Recommendation format guidelines
- [ ] Sample findings report
- [ ] SUS score calculation sheet
- [ ] Bot assessment schedule and instructions
- [ ] AI transparency log template

### Classroom Setup | 教室セットアップ
- [ ] Ensure students can access their test participants
- [ ] Prepare for bilingual presentation (English/Japanese)
- [ ] Set up for hands-on activity transition
- [ ] Have backup materials for students without devices
- [ ] Arrange space for simultaneous testing sessions

---

## Slide-by-Slide Speaking Points | スライド別スピーキングポイント

### Slide 1: Welcome to Week 11! | 第11週へようこそ！

#### Opening (2 minutes) | オープニング（2分）

**English Speaking Points:**
- "Welcome to Week 11! We're in the home stretch now. Last week you planned your usability tests - today you'll actually conduct them and analyze the results."
- "This is where things get real. You're going to see actual users interact with your prototypes, and you'll discover things you never expected."
- "By the end of today, you'll have real usability data and a clear roadmap for improving your designs."
- "Plus, you'll have your first bot-conducted assessment - a conversational interview about HCI principles."

**Japanese Speaking Points:**
- "第11週へようこそ！私たちは今、ホームストレッチにいます。先週はユーザビリティテストを計画しました - 今日は実際にそれらを実施し、結果を分析します。"
- "ここで物事が本物になります。実際のユーザーがプロトタイプとどのように相互作用するかを見ることになり、予想もしなかったことを発見するでしょう。"
- "今日の終わりまでに、実際のユーザビリティデータとデザインを改善するための明確なロードマップを持つことになります。"
- "さらに、HCI原則に関する会話インタビューである最初のボット実施評価があります。"

**Key Points to Emphasize:**
- Transition from planning to execution
- Real user testing today
- Analysis skills are critical
- Bot assessment is conversational, not scary

---

### Slide 2: From Testing to Analysis | テストから分析へ

#### Bridge Between Weeks (3 minutes) | 週間のブリッジ（3分）

**English Speaking Points:**
- "Last week you created test plans - the what, who, when, and how of testing. Today you execute those plans and make sense of the data."
- "Testing without analysis is just watching people use your design. Analysis is what transforms observations into actionable improvements."
- "Think about it: if five people can't find your search button, that's not a coincidence - that's a design problem that needs fixing."
- "Your goal today is to go from 'User 3 struggled with checkout' to 'The checkout button needs to be 20% larger and moved above the fold because 80% of users couldn't find it.'"

**Japanese Speaking Points:**
- "先週、テスト計画を作成しました - テストの何を、誰が、いつ、どのようにするか。今日はそれらの計画を実行し、データの意味を理解します。"
- "分析のないテストは、人々があなたのデザインを使用するのを見ているだけです。分析は観察を実行可能な改善に変換するものです。"
- "考えてみてください：5人が検索ボタンを見つけられない場合、それは偶然ではありません - それは修正が必要なデザイン問題です。"
- "今日の目標は、「ユーザー3がチェックアウトで苦労した」から「チェックアウトボタンは80%のユーザーが見つけられなかったため、20%大きくし、フォールドの上に移動する必要がある」に移行することです。"

**Interactive Elements:**
- Ask: "How many of you have ever struggled with an interface and thought 'why didn't they just...?'"
- Discuss: "That's exactly what you're learning to prevent today."
- Emphasize: "You're becoming the designer who doesn't make those mistakes."

---

### Slide 3: Analyzing Quantitative Data | 定量的データの分析

#### Metrics Deep Dive (4 minutes) | メトリクス詳細（4分）

**English Speaking Points:**
- "Let's start with the numbers - quantitative data. Three core metrics: task success rate, time on task, and error rate."
- "Task success rate is your most important metric. If users can't complete tasks, nothing else matters. The benchmark is 78% - that's industry standard."
- "Below 78%? You have work to do. Below 50%? You have serious usability problems that must be fixed before launch."
- "Time on task tells you about efficiency. If something takes 5 minutes when it should take 1 minute, users are confused or the workflow is broken."
- "But be careful: fast isn't always good. Maybe they skipped important steps. Context matters."
- "Error rate shows where users stumble. A high error rate means your interface is misleading or confusing."

**Japanese Speaking Points:**
- "数字から始めましょう - 定量的データ。3つのコアメトリクス：タスク成功率、タスク時間、エラー率。"
- "タスク成功率は最も重要なメトリクスです。ユーザーがタスクを完了できない場合、他には何も重要ではありません。ベンチマークは78% - それが業界標準です。"
- "78%未満？あなたはやるべきことがあります。50%未満？起動前に修正する必要がある深刻なユーザビリティ問題があります。"
- "タスク時間は効率について教えてくれます。1分かかるべきものが5分かかる場合、ユーザーは混乱しているか、ワークフローが壊れています。"
- "しかし注意してください：速いことが常に良いわけではありません。おそらく重要なステップをスキップしました。コンテキストが重要です。"
- "エラー率はユーザーがつまずく場所を示します。高いエラー率は、インターフェースが誤解を招くまたは混乱していることを意味します。"

**Calculation Examples:**
- Walk through the example: "5 participants, 5 tasks each = 25 attempts. 20 successful = 80% success rate."
- Show time calculation: "User 1: 2.5 min, User 2: 3.1 min, User 3: 1.8 min, User 4: 2.7 min, User 5: 2.2 min. Average: 2.46 minutes."
- Discuss: "Is 2.46 minutes good? Depends on the task complexity."

---

### Slide 4: Analyzing Qualitative Data | 定性的データの分析

#### Beyond Numbers (3 minutes) | 数字を超えて（3分）

**English Speaking Points:**
- "Numbers tell you what happened. Qualitative data tells you why it happened."
- "User quotes are gold. When someone says 'I can't find the search button,' that's direct evidence of a usability problem."
- "Group similar quotes together. If three people say variations of 'Where's the price filter?', you've found a pattern."
- "Behavior analysis is crucial. Watch for hesitation - when users pause, they're confused or uncertain."
- "Did they take the expected navigation path? If not, why? Maybe your interface suggests a different mental model."
- "Body language matters too. Frustration, confusion, delight - all tell you about the user experience."

**Japanese Speaking Points:**
- "数字は何が起こったかを教えてくれます。定性的データはなぜそれが起こったかを教えてくれます。"
- "ユーザーの引用は金です。誰かが「検索ボタンが見つからない」と言った場合、それはユーザビリティ問題の直接的な証拠です。"
- "類似の引用をグループ化します。3人が「価格フィルターはどこですか？」のバリエーションを言う場合、パターンを見つけました。"
- "行動分析は重要です。躊躇を観察してください - ユーザーが一時停止するとき、彼らは混乱しているか不確かです。"
- "彼らは予想されるナビゲーションパスを取りましたか？そうでない場合、なぜですか？おそらくあなたのインターフェースは異なるメンタルモデルを示唆しています。"
- "ボディランゲージも重要です。フラストレーション、混乱、喜び - すべてがユーザー体験について教えてくれます。"

**Pattern Recognition:**
- "The magic number is 3. If three or more participants show the same behavior, it's a pattern, not a coincidence."
- "One user struggling might be an outlier. Three users struggling is a design problem."

---

### Slide 5: Finding Patterns Across Participants | 参加者間のパターンの発見

#### Triangulation (3 minutes) | トライアンギュレーション（3分）

**English Speaking Points:**
- "Triangulation means combining multiple data sources to see the complete picture."
- "You have quantitative metrics, behavioral observations, and user quotes. Put them together."
- "Example: Task success rate is 40%. Four out of five users scrolled past the filter. Three users asked 'where's the price option?' Average time was 3x expected."
- "All of this points to one conclusion: the price filter has a serious visibility problem."
- "Strong patterns - 5 out of 5 users affected - are your highest priority. These are critical issues."
- "Moderate patterns - 3 to 4 users affected - are still important but medium priority."
- "Weak patterns - 1 to 2 users - might be outliers or edge cases. Still worth noting, but lower priority."

**Japanese Speaking Points:**
- "トライアンギュレーションは、完全な絵を見るために複数のデータソースを組み合わせることを意味します。"
- "定量的メトリクス、行動観察、ユーザー引用があります。それらをまとめてください。"
- "例：タスク成功率は40%です。5人のうち4人がフィルターを見ずにスクロールしました。3人のユーザーが「価格オプションはどこですか？」と尋ねました。平均時間は予想の3倍でした。"
- "これらすべては1つの結論を指しています：価格フィルターには深刻な可視性の問題があります。"
- "強いパターン - 5人のうち5人のユーザーが影響を受ける - は最優先事項です。これらは重大な問題です。"
- "中程度のパターン - 3〜4人のユーザーが影響を受ける - は依然として重要ですが、中優先度です。"
- "弱いパターン - 1〜2人のユーザー - は外れ値またはエッジケースかもしれません。それでも注目する価値がありますが、優先度は低いです。"

**Emphasize:**
- Don't ignore weak patterns completely - they might reveal accessibility issues or edge cases
- Always look for convergence between different data types

---

### Slide 6: Severity Rating Framework | 重大度評価フレームワーク

#### Jakob Nielsen's Framework (3 minutes) | Jakob Nielsenのフレームワーク（3分）

**English Speaking Points:**
- "Not all problems are equal. Some are catastrophic, some are minor. Jakob Nielsen created a 0-4 severity rating scale that's industry standard."
- "0 means it's not actually a usability problem - just personal preference. Ignore these."
- "1 is cosmetic - fix if you have extra time. Example: a minor color inconsistency that doesn't affect function."
- "2 is a minor usability problem. It causes slight delays but users eventually figure it out. Low priority."
- "3 is a major usability problem. High priority. It causes significant frustration and affects most users. Example: hidden navigation that's hard to discover."
- "4 is a catastrophe. Critical priority. Must fix before launch. It prevents task completion. Example: a broken checkout flow in an e-commerce app."

**Japanese Speaking Points:**
- "すべての問題が等しいわけではありません。いくつかは壊滅的で、いくつかは軽微です。Jakob Nielsenは業界標準の0-4の重大度評価スケールを作成しました。"
- "0はそれが実際にはユーザビリティ問題ではないことを意味します - 単なる個人的な好みです。これらは無視してください。"
- "1は表面的です - 追加の時間がある場合に修正します。例：機能に影響しない軽微な色の不一致。"
- "2は軽微なユーザビリティ問題です。わずかな遅延を引き起こしますが、ユーザーは最終的にそれを理解します。低優先度。"
- "3は主要なユーザビリティ問題です。高優先度。重大なフラストレーションを引き起こし、ほとんどのユーザーに影響します。例：発見が困難な隠されたナビゲーション。"
- "4は壊滅的です。重大優先度。起動前に修正する必要があります。タスク完了を妨げます。例：電子商取引アプリの壊れたチェックアウトフロー。"

**Real-World Examples:**
- Show examples of each severity level from familiar apps
- Discuss: "What severity would you give to [specific example]?"

---

### Slide 7: Prioritization Matrix | 優先順位付けマトリックス

#### Two-Dimensional Thinking (3 minutes) | 二次元思考（3分）

**English Speaking Points:**
- "Severity alone isn't enough. You also need to consider frequency - how many users are affected?"
- "The priority matrix combines frequency and impact. High frequency + critical impact = P1, must fix immediately."
- "Think about it: a critical bug that only one user encountered in edge case is less urgent than a major issue affecting 90% of users."
- "P1 issues: High frequency, critical impact. Drop everything and fix these. Example: search function doesn't work."
- "P2 issues: High frequency major impact OR medium frequency critical impact. Fix in next iteration."
- "P3 issues: Medium frequency minor impact OR low frequency major impact. Address if time permits."
- "P4 issues: Low frequency, minor impact. Backlog for future consideration."

**Japanese Speaking Points:**
- "重大度だけでは十分ではありません。頻度も考慮する必要があります - 何人のユーザーが影響を受けますか？"
- "優先度マトリックスは頻度と影響を組み合わせます。高頻度 + 重大な影響 = P1、すぐに修正する必要があります。"
- "考えてみてください：エッジケースで1人のユーザーだけが遭遇した重大なバグは、90%のユーザーに影響する主要な問題よりも緊急性が低いです。"
- "P1の問題：高頻度、重大な影響。すべてを中断してこれらを修正してください。例：検索機能が動作しません。"
- "P2の問題：高頻度の主要な影響または中頻度の重大な影響。次の反復で修正します。"
- "P3の問題：中頻度の軽微な影響または低頻度の主要な影響。時間があれば対処します。"
- "P4の問題：低頻度、軽微な影響。将来の検討のためのバックログ。"

**Matrix Visualization:**
- Draw the matrix on board if possible
- Plot example issues to demonstrate prioritization

---

### Slide 8: Root Cause Analysis | 根本原因分析

#### The "5 Whys" (2 minutes) | 「5つのなぜ」（2分）

**English Speaking Points:**
- "Don't just fix symptoms - fix root causes. The '5 Whys' technique helps you dig deeper."
- "Walk through the example: Users can't complete checkout. Why? Can't find button. Why? It's below the fold. Why? Too much info above. Why? We wanted single screen. Why? Unvalidated assumption about user preference."
- "The root cause isn't 'button placement' - it's 'design decision based on unvalidated assumption.'"
- "The fix isn't just moving the button - it's changing how we make design decisions: test assumptions, prioritize critical actions, use progressive disclosure."
- "This prevents the same root cause from creating different symptoms elsewhere in your design."

**Japanese Speaking Points:**
- "症状を修正するだけでなく、根本原因を修正してください。「5つのなぜ」技法はより深く掘り下げるのに役立ちます。"
- "例を見てみましょう：ユーザーがチェックアウトを完了できません。なぜですか？ボタンが見つかりません。なぜですか？フォールドの下にあります。なぜですか？上に情報が多すぎます。なぜですか？単一画面が必要でした。なぜですか？ユーザーの好みに関する検証されていない仮定。"
- "根本原因は「ボタンの配置」ではありません - それは「検証されていない仮定に基づくデザイン決定」です。"
- "修正はボタンを移動するだけではありません - デザイン決定の方法を変えることです：仮定をテストし、重要なアクションに優先順位を付け、段階的開示を使用します。"
- "これにより、同じ根本原因がデザインの他の場所で異なる症状を作成するのを防ぎます。"

---

### Slide 9: Creating Actionable Recommendations | 実行可能な推奨事項の作成

#### From Problems to Solutions (3 minutes) | 問題から解決策へ（3分）

**English Speaking Points:**
- "A good recommendation is specific, actionable, evidence-based, prioritized, and user-centered."
- "Bad recommendation: 'Make navigation better.' What does that even mean? How do you do it?"
- "Good recommendation: 'Move main menu icon to top-left corner and increase size to 44×44 px to meet touch target standards, based on 4/5 users failing to notice current 32px icon.'"
- "See the difference? The good recommendation tells you exactly what to do, why to do it, and backs it up with data."
- "Always reference your evidence. '4/5 users couldn't find this' is much more compelling than 'I think this should change.'"
- "User-centered means focusing on user needs, not your preferences as a designer."

**Japanese Speaking Points:**
- "良い推奨事項は具体的で、実行可能で、証拠に基づき、優先順位が付けられ、ユーザー中心です。"
- "悪い推奨事項：「ナビゲーションをより良くする。」それは何を意味しますか？どうやってそれをしますか？"
- "良い推奨事項：「メインメニューアイコンを左上隅に移動し、タッチターゲット基準を満たすためにサイズを44×44 pxに増やします。これは4/5人のユーザーが現在の32pxアイコンに気付かなかったことに基づいています。」"
- "違いがわかりますか？良い推奨事項は正確に何をすべきか、なぜそれをすべきかを教え、データでそれを裏付けます。"
- "常に証拠を参照してください。「4/5人のユーザーがこれを見つけられなかった」は「これを変更すべきだと思う」よりもはるかに説得力があります。"
- "ユーザー中心とは、デザイナーとしてのあなたの好みではなく、ユーザーニーズに焦点を当てることを意味します。"

**Template Review:**
- Walk through the recommendation template on slide
- Emphasize each component: issue, priority, evidence, root cause, recommendation, expected impact

---

### Slide 10: Recommendation Template | 推奨事項テンプレート

#### Structured Format (2 minutes) | 構造化形式（2分）

**English Speaking Points:**
- "Use this template for every recommendation. It ensures you include all critical information."
- "Start with a clear issue title. 'Price filter visibility problem' is better than 'filter issue.'"
- "State priority clearly: P1, P2, P3, or P4. This helps with implementation planning."
- "Evidence section is crucial. List all supporting data: metrics, participant counts, quotes, times."
- "Root cause explains why the problem exists. This prevents band-aid solutions."
- "Recommendations should be numbered, specific steps. Multiple actions are often needed."
- "Expected impact shows the value of fixing this. It helps justify the effort."

**Japanese Speaking Points:**
- "すべての推奨事項にこのテンプレートを使用してください。すべての重要な情報を含めることを保証します。"
- "明確な問題タイトルから始めます。「価格フィルターの可視性の問題」は「フィルターの問題」よりも優れています。"
- "優先度を明確に述べます：P1、P2、P3、またはP4。これは実装計画に役立ちます。"
- "証拠セクションは重要です。すべてのサポートデータをリストします：メトリクス、参加者数、引用、時間。"
- "根本原因は問題が存在する理由を説明します。これは絆創膏ソリューションを防ぎます。"
- "推奨事項は番号付きの特定のステップである必要があります。複数のアクションが必要な場合が多いです。"
- "予想される影響はこれを修正する価値を示します。それは努力を正当化するのに役立ちます。"

---

### Slide 11: Types of Design Improvements | デザイン改善の種類

#### Effort vs. Impact (2 minutes) | 労力対影響（2分）

**English Speaking Points:**
- "Not all fixes take the same effort. Quick fixes - label changes, color adjustments - can be done in hours."
- "Interface refinements like navigation restructuring take days or weeks but have high impact."
- "Feature additions require significant effort and time. Only do these if testing shows they're truly needed."
- "Fundamental redesigns mean you have major problems. Avoid if possible - they require months and new testing."
- "Focus on quick fixes first - low effort, high impact. These give you the best return on investment."
- "For your projects, prioritize P1 and P2 issues. You have limited time, so focus on what matters most."

**Japanese Speaking Points:**
- "すべての修正が同じ労力を必要とするわけではありません。クイックフィックス - ラベル変更、色調整 - は数時間で行うことができます。"
- "ナビゲーション再構築のようなインターフェース改良には数日または数週間かかりますが、高い影響があります。"
- "機能追加には重要な労力と時間が必要です。テストで本当に必要であることが示された場合にのみこれらを行ってください。"
- "基本的な再設計は主要な問題があることを意味します。可能であれば避けてください - 数か月と新しいテストが必要です。"
- "最初にクイックフィックスに焦点を当てます - 低労力、高影響。これらは最高の投資収益率を提供します。"
- "プロジェクトについては、P1とP2の問題に優先順位を付けてください。時間が限られているので、最も重要なことに焦点を当ててください。"

---

### Slide 12: Communicating Findings | 調査結果の伝達

#### Stakeholder Presentation (2 minutes) | ステークホルダープレゼンテーション（2分）

**English Speaking Points:**
- "In the real world, you'll present findings to stakeholders - managers, clients, developers. Your report needs to be clear and compelling."
- "Start with an executive summary: overall usability score, top 3-5 issues, high-priority recommendations."
- "Use visuals: charts, graphs, user quotes, even video clips of users struggling. These are powerful."
- "Structure your report logically: methodology, results, findings, prioritized issues, recommendations, next steps."
- "Remember your audience. Executives want the bottom line. Developers want specific fixes. Designers want context."
- "Your job is to advocate for users. Make their problems visible and understood."

**Japanese Speaking Points:**
- "実世界では、ステークホルダー - マネージャー、クライアント、開発者 - に調査結果を提示します。レポートは明確で説得力のある必要があります。"
- "エグゼクティブサマリーから始めます：全体的なユーザビリティスコア、上位3-5の問題、高優先度の推奨事項。"
- "ビジュアルを使用します：チャート、グラフ、ユーザー引用、さらにはユーザーが苦労しているビデオクリップ。これらは強力です。"
- "レポートを論理的に構成します：方法論、結果、調査結果、優先順位付けされた問題、推奨事項、次のステップ。"
- "聴衆を覚えておいてください。経営幹部は最終結果を望んでいます。開発者は特定の修正を望んでいます。デザイナーはコンテキストを望んでいます。"
- "あなたの仕事はユーザーを擁護することです。彼らの問題を見えるようにし、理解されるようにします。"

---

### Slide 13: Iterative Design Cycle | 反復デザインサイクル

#### Continuous Improvement (2 minutes) | 継続的改善（2分）

**English Speaking Points:**
- "Design is never done. It's a continuous cycle: design, test, analyze, prioritize, redesign, test again."
- "Each iteration improves the design. First test reveals major issues. Fix those. Second test reveals more subtle issues."
- "This is why we say 'fail fast, learn fast.' The sooner you test, the sooner you discover problems, the sooner you can fix them."
- "In the real world, products are constantly evolving based on user feedback and testing."
- "For your projects, you'll do at least one test-analyze-improve cycle. Time permitting, test again to validate improvements."
- "Remember: a design that's 'done' is a design that's no longer relevant to users."

**Japanese Speaking Points:**
- "デザインは決して完成しません。それは継続的なサイクルです：デザイン、テスト、分析、優先順位付け、再設計、再度テスト。"
- "各反復がデザインを改善します。最初のテストは主要な問題を明らかにします。それらを修正します。2回目のテストはより微妙な問題を明らかにします。"
- "これが「早く失敗し、早く学ぶ」と言う理由です。早くテストすればするほど、早く問題を発見し、早く修正できます。"
- "実世界では、製品はユーザーフィードバックとテストに基づいて常に進化しています。"
- "プロジェクトについては、少なくとも1回のテスト-分析-改善サイクルを行います。時間が許せば、再度テストして改善を検証します。"
- "覚えておいてください：「完成した」デザインは、もはやユーザーに関連性がないデザインです。"

---

### Slide 14: Common Analysis Mistakes to Avoid | 避けるべき一般的な分析ミス

#### Pitfalls (3 minutes) | 落とし穴（3分）

**English Speaking Points:**
- "Let's talk about common mistakes. First: confirmation bias. Don't only see data that confirms your design was good. Actively look for problems."
- "Cherry-picking data is dishonest. If four users hated the navigation and one liked it, you can't just report the positive quote."
- "Don't ignore outliers. That 'one weird user' might reveal an accessibility issue or edge case worth addressing."
- "Vague recommendations are useless. 'Make it better' doesn't help anyone. Be specific."
- "Analysis paralysis is real. Don't over-analyze forever. Set a deadline, prioritize, and move to action."
- "And here's the big one: defending your design. If users don't understand it, it's a design problem, not a user problem. Your ego needs to step aside."

**Japanese Speaking Points:**
- "一般的な間違いについて話しましょう。最初：確証バイアス。デザインが良かったことを確認するデータのみを見ないでください。積極的に問題を探してください。"
- "データのチェリーピッキングは不誠実です。4人のユーザーがナビゲーションを嫌い、1人が好きだった場合、ポジティブな引用だけを報告することはできません。"
- "外れ値を無視しないでください。その「1人の奇妙なユーザー」は、対処する価値のあるアクセシビリティ問題またはエッジケースを明らかにするかもしれません。"
- "曖昧な推奨事項は役に立ちません。「より良くする」は誰にも役立ちません。具体的にしてください。"
- "分析麻痺は現実です。永遠に過剰分析しないでください。締め切りを設定し、優先順位を付け、行動に移ります。"
- "そしてこれが大きなものです：デザインを擁護すること。ユーザーが理解しない場合、それはユーザー問題ではなくデザイン問題です。あなたのエゴは脇に置く必要があります。"

**Student Engagement:**
- Ask: "Has anyone ever defended a design choice when they knew deep down it wasn't working?"
- Discuss: "It's natural to be attached to your work, but your job is to serve users, not your ego."

---

### Slide 15: Your Turn: Analyzing Test Results | あなたの番：テスト結果の分析

#### Activity Introduction (2 minutes) | アクティビティ紹介（2分）

**English Speaking Points:**
- "Now it's your turn! You have 60 minutes for two parts: conducting tests and analyzing results."
- "Part 1: 30 minutes to actually test your prototypes with 2-3 participants. Use your test plan from last week."
- "Apply the think-aloud protocol. Encourage participants to speak their thoughts. Stay neutral - don't help or defend."
- "Document everything: task success, time, errors, SUS scores, observations, quotes."
- "Part 2: 30 minutes to analyze your data. Calculate metrics, identify patterns, rate severity, prioritize, create 3-5 recommendations."
- "The bot will guide you through analysis templates and frameworks. Use them!"
- "Your deliverable today: a usability findings report with clear, actionable recommendations."

**Japanese Speaking Points:**
- "今、あなたの番です！2つのパートに60分あります：テストの実施と結果の分析。"
- "パート1：2-3人の参加者で実際にプロトタイプをテストするために30分。先週のテスト計画を使用してください。"
- "シンクアラウドプロトコルを適用します。参加者に思考を話すように奨励します。中立を保ってください - 助けたり擁護したりしないでください。"
- "すべてを文書化します：タスク成功、時間、エラー、SUSスコア、観察、引用。"
- "パート2：データを分析するために30分。メトリクスを計算し、パターンを特定し、重大度を評価し、優先順位を付け、3-5の推奨事項を作成します。"
- "ボットが分析テンプレートとフレームワークを案内します。それらを使用してください！"
- "今日の成果物：明確で実行可能な推奨事項を含むユーザビリティ調査結果レポート。"

**Logistics:**
- Explain testing space arrangements
- Clarify submission requirements
- Answer logistical questions

---

### Slide 16: Bot-Conducted Assessment | ボット実施評価

#### Conversational Interview (2 minutes) | 会話インタビュー（2分）

**English Speaking Points:**
- "After your activity, you'll have a bot-conducted assessment. This is new - it's a conversational interview, not a quiz."
- "The bot will ask about your design choices, testing process, and HCI principles. This is 15-20 minutes."
- "Topics include usability testing methodology, metrics analysis, design rationale, and prioritization frameworks."
- "Be ready to explain your decisions. Why did you prioritize that issue? What evidence supports your recommendation?"
- "This isn't scary! The bot is evaluating your understanding of HCI principles and your ability to justify design decisions with evidence."
- "Important: This is individual assessment. External AI chatbots are NOT allowed during the assessment. Just you and the HCI-101 Bot."

**Japanese Speaking Points:**
- "アクティビティの後、ボット実施評価があります。これは新しいものです - クイズではなく会話インタビューです。"
- "ボットがデザイン選択、テストプロセス、HCI原則について尋ねます。これは15-20分です。"
- "トピックには、ユーザビリティテスト方法論、メトリクス分析、デザイン根拠、優先順位付けフレームワークが含まれます。"
- "決定を説明する準備をしてください。なぜその問題に優先順位を付けましたか？どのような証拠が推奨事項をサポートしますか？"
- "これは怖くありません！ボットはHCI原則の理解と証拠でデザイン決定を正当化する能力を評価しています。"
- "重要：これは個別評価です。評価中は外部AIチャットボットは許可されていません。あなたとHCI-101ボットだけです。"

**Preparation Tips:**
- Review your test results
- Be ready to articulate your reasoning
- Practice explaining usability issues clearly
- Understand your prioritization rationale

---

### Slide 17: Key Takeaways | 重要なポイント

#### Closing (2 minutes) | クロージング（2分）

**English Speaking Points:**
- "Let's recap the key takeaways from today."
- "First: Analysis transforms data into insights. Raw numbers aren't enough - you need to interpret and find patterns."
- "Second: Prioritization is essential. You can't fix everything. Use severity ratings and the frequency-impact matrix."
- "Third: Recommendations must be actionable. Specific, evidence-based, prioritized, user-centered."
- "Fourth: Design is iterative. Test, analyze, redesign, test again. Each cycle improves your design."
- "Next week: Accessibility and Inclusive Design. You'll learn to design for all users, including those with disabilities."
- "This is crucial - good design works for everyone, not just able-bodied users."

**Japanese Speaking Points:**
- "今日の重要なポイントを要約しましょう。"
- "最初：分析はデータを洞察に変換します。生の数字だけでは十分ではありません - 解釈してパターンを見つける必要があります。"
- "2番目：優先順位付けは不可欠です。すべてを修正することはできません。重大度評価と頻度-影響マトリックスを使用します。"
- "3番目：推奨事項は実行可能でなければなりません。具体的で、証拠に基づき、優先順位が付けられ、ユーザー中心です。"
- "4番目：デザインは反復的です。テスト、分析、再設計、再度テスト。各サイクルがデザインを改善します。"
- "来週：アクセシビリティと包括的デザイン。障害を持つユーザーを含むすべてのユーザーのためにデザインする方法を学びます。"
- "これは重要です - 良いデザインは健常者だけでなく、すべての人のために機能します。"

**Final Encouragement:**
- "You're becoming real UX researchers and designers!"
- "The insights you gain from testing are invaluable."
- "Trust the data, serve the users, iterate continuously."

---

## Post-Lecture Activities | 講義後アクティビティ

### Immediate Next Steps | 即座の次のステップ

1. **Set Up Testing Environment** | テスト環境をセットアップ
   - Ensure adequate space for simultaneous testing
   - Verify all students have access to test participants
   - Prepare observation templates and materials
   - Set up bot assessment scheduling

2. **Distribute Materials** | 教材を配布
   - Analysis templates (severity rating, priority matrix)
   - Recommendation format guidelines
   - SUS calculation sheets
   - Bot assessment instructions

3. **Monitor Testing Sessions** | テストセッションを監視
   - Circulate during testing
   - Ensure proper think-aloud protocol usage
   - Help with technical issues only
   - Remind students to stay neutral

### Activity Support | アクティビティサポート

**During Part 1 (Testing - 30 min):**
- Observe student moderation skills
- Intervene only if serious issues arise
- Remind students to document everything
- Help coordinate participant scheduling if needed

**During Part 2 (Analysis - 30 min):**
- Guide students through analysis templates
- Help with metric calculations if needed
- Encourage pattern recognition
- Review recommendation quality
- Direct students to bot for guidance

### Common Issues to Watch For | 注意すべき一般的な問題

- **Helping participants** | 参加者を助ける: Students may want to "save" struggling users - remind them to observe, not intervene
- **Insufficient data** | 不十分なデータ: Some students may not collect enough detail - check their notes
- **Confirmation bias** | 確証バイアス: Watch for students ignoring negative findings
- **Vague recommendations** | 曖昧な推奨事項: Push for specificity
- **Over-analysis** | 過剰分析: Some students may get stuck - set time limits

### Support Strategies | サポート戦略

- **Bilingual Support** | バイリンガルサポート: Provide explanations in both languages as needed
- **Template Guidance** | テンプレートガイダンス: Show examples of well-completed templates
- **Bot Direction** | ボット指示: Remind students the bot can help with analysis frameworks
- **Time Management** | 時間管理: Keep students on track for both parts

---

## Bot-Conducted Assessment Management | ボット実施評価管理

### Assessment Scheduling | 評価スケジューリング

**Timing Options:**
- End of class session (if time permits)
- After activity completion
- As homework/take-home assessment
- Flexible scheduling within week

**Logistics:**
- Ensure all students know how to access assessment
- Clarify time limit (15-20 minutes)
- Emphasize individual work requirement
- No external AI allowed during assessment

### Assessment Topics | 評価トピック

**Key Areas the Bot Will Assess:**
1. **Usability Testing Methodology**
   - Understanding of testing procedures
   - Think-aloud protocol application
   - Participant selection rationale

2. **Metrics and Analysis**
   - Ability to calculate and interpret metrics
   - Pattern recognition across participants
   - Triangulation of data sources

3. **Design Decision Rationale**
   - Justification for design choices
   - Evidence-based reasoning
   - User-centered thinking

4. **Prioritization Frameworks**
   - Application of severity ratings
   - Use of frequency-impact matrix
   - Understanding of P1-P4 prioritization

### Student Preparation Guidance | 学生準備ガイダンス

**Advise Students to:**
- Review test results thoroughly before assessment
- Be ready to explain design decisions
- Practice articulating usability issues clearly
- Understand their prioritization rationale
- Have examples ready from their testing

### Assessment Support | 評価サポート

- Make yourself available for pre-assessment questions
- Clarify assessment format and expectations
- Provide examples of good vs. poor responses
- Reassure students this is conversational, not adversarial

---

## Deliverables and Grading | 成果物と評価

### Today's Deliverable | 今日の成果物

**Usability Findings Report**

**Required Components:**
1. **Executive Summary**
   - Overall usability score (SUS average)
   - Top 3-5 critical issues identified
   - High-priority recommendations

2. **Methodology**
   - Number of participants
   - Testing procedures
   - Tasks evaluated

3. **Quantitative Results**
   - Task success rates (per task and overall)
   - Average time on task
   - Error rates
   - SUS scores

4. **Qualitative Findings**
   - Key observations
   - User quotes (organized by theme)
   - Behavioral patterns

5. **Prioritized Issues**
   - Each issue with severity rating (0-4)
   - Priority level (P1-P4)
   - Frequency data (% of users affected)

6. **Recommendations**
   - 3-5 specific, actionable recommendations
   - Evidence supporting each
   - Expected impact
   - Using provided template format

7. **AI Transparency Documentation**
   - All external AI prompts and responses
   - Verification process
   - How AI assistance was used

**Format:** 4-6 page document with clear sections

**Submission:** [Specify submission method and deadline]

### Grading Criteria | 評価基準

**Usability Findings Report (Weighted in Weekly Activities 40%):**
- Data Collection Quality (20%): Complete metrics, detailed observations
- Analysis Depth (25%): Pattern identification, triangulation, severity ratings
- Recommendation Quality (30%): Specific, actionable, evidence-based, prioritized
- Presentation (15%): Clear structure, professional format, visual aids
- AI Transparency (10%): Complete documentation of AI usage

**Bot Assessment (Part of Bot Assessments 15%):**
- Understanding of usability testing methods
- Ability to analyze and interpret test data
- Evidence-based design reasoning
- Application of prioritization frameworks
- Clear communication of findings

---

## Resources for Next Week | 来週のためのリソース

### Week 12 Preview: Accessibility and Inclusive Design | 第12週プレビュー：アクセシビリティと包括的デザイン

**Topics to Cover:**
- WCAG 2.1 guidelines and standards
- Designing for visual impairments (screen readers, color contrast)
- Motor disability considerations (touch targets, keyboard navigation)
- Cognitive accessibility (clear language, consistent layouts)
- Assistive technologies overview
- Accessibility testing tools (WAVE, axe, Lighthouse)

**Student Preparation:**
- Ask students to explore accessibility settings on their devices
- Encourage trying screen readers or voice control
- Reflect on accessibility barriers they've encountered

### Additional Resources | 追加リソース

**For Students:**
- Jakob Nielsen's severity rating guidelines
- Priority matrix templates
- Sample usability findings reports
- SUS calculation tools
- Analysis frameworks

**For Instructor:**
- Next week's materials on accessibility
- WCAG guideline summaries
- Accessibility audit templates
- Guest speaker possibilities (accessibility experts)

---

## Reflection and Adaptation | 振り返りと適応

### Post-Class Reflection Questions | クラス後の振り返り質問

**For Instructor:**
- Did students successfully conduct usability tests?
- Were they able to identify meaningful patterns?
- Did they create specific, actionable recommendations?
- How was the quality of their analysis?
- Were severity ratings and prioritization applied correctly?
- How did the bot assessment go?
- What needs more emphasis next time?

**For Students (Optional Reflection Prompt):**
- What surprised you most during testing?
- What was hardest about analyzing results?
- How did your assumptions about your design change?
- What will you do differently in your next iteration?

### Continuous Improvement Notes | 継続的改善ノート

**What Worked Well:**
- [Document successful elements]
- [Note effective teaching strategies]
- [Record good student examples]

**What Needs Adjustment:**
- [Identify challenging concepts]
- [Note time management issues]
- [Plan modifications for next offering]

**Student Feedback Integration:**
- [Collect and analyze student feedback]
- [Identify common challenges]
- [Plan support strategies]

---

## Emergency Procedures | 緊急手順

### Technical Issues | 技術的問題

- **Bot Portal Down** | ボットポータルダウン:
  - Have offline assessment alternative ready
  - Provide manual analysis templates
  - Reschedule bot assessment if needed

- **Participant No-Shows** | 参加者不参加:
  - Have backup plan for students to test each other's prototypes
  - Allow flexible testing times within the week
  - Instructor can serve as participant if absolutely necessary

- **Tool Access Problems** | ツールアクセス問題:
  - Have paper-based analysis templates
  - Provide alternative submission methods
  - Allow extended deadlines if widespread issue

### Student Issues | 学生の問題

- **Insufficient Test Data** | 不十分なテストデータ:
  - Provide guidance on minimum data requirements
  - Allow additional testing time if needed
  - Help student recruit additional participants

- **Analysis Struggles** | 分析の苦労:
  - Provide one-on-one support during activity
  - Direct to bot for guided analysis
  - Offer office hours assistance

- **Assessment Anxiety** | 評価不安:
  - Clarify conversational nature of bot assessment
  - Provide practice questions
  - Emphasize learning over perfect performance

---

*End of Instructor Notes*

**Course:** HCI-101 | **Instructor:** Yuri Tijerino | **Fall 2025**
