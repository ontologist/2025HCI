# PowerPoint Template for Week 11 HCI Lecture
# 第11週HCI講義用PowerPointテンプレート

## How to Use This Template:
1. Open PowerPoint or Google Slides
2. Create new presentation
3. Copy content from each slide section below
4. Add visual elements and formatting
5. Save as "Week11-Testing-Analysis.pptx"

---

## Slide 1: Title Slide
**Title:** Week 11: Conducting Tests and Analyzing Results
**Title (JP):** 第11週：テスト実施と結果分析
**Subtitle:** Transforming User Research into Actionable Insights
**Subtitle (JP):** ユーザー調査を実行可能な洞察に変換する
**Instructor:** Yuri Tijerino
**Date:** Fall 2025 | 2025年秋学期

**Visual Elements to Add:**
- Data analysis or testing icons
- Modern, clean design
- Bilingual text layout

---

## Slide 2: Today's Agenda
**Title:** Today's Agenda | 今日のアジェンダ

**Bullet Points:**
- Conducting Real Usability Tests | 実際のユーザビリティテストの実施
- Analyzing Test Results | テスト結果の分析
- Finding Patterns Across Participants | 参加者間のパターンの発見
- Prioritizing Usability Issues | ユーザビリティ問題の優先順位付け
- Creating Actionable Recommendations | 実行可能な推奨事項の作成
- Bot-Conducted Assessment | ボット実施評価

**Learning Objectives:**
By the end of today, you will:
- Synthesize qualitative and quantitative test data
- Identify patterns and recurring issues
- Apply severity rating frameworks
- Create specific, actionable recommendations

**Visual Elements:**
- Checklist or agenda graphic
- Icons for each agenda item

---

## Slide 3: From Testing to Analysis
**Title:** From Testing to Analysis | テストから分析へ

**Two-Column Layout:**

**Left Column - Week 10:**
- Planning tests
- Creating test protocols
- Defining success metrics
- Preparing materials

**Right Column - Week 11:**
- Executing tests
- Collecting data
- Analyzing results
- Creating recommendations

**Why Analysis Matters:**
- Raw data isn't enough | 生データだけでは十分ではない
- Patterns reveal truth | パターンが真実を明らかにする
- Prioritization is essential | 優先順位付けは不可欠
- Recommendations drive action | 推奨事項が行動を促進

**Visual Elements:**
- Timeline or journey map
- Before/after comparison
- Analysis process diagram

---

## Slide 4: Analyzing Quantitative Data
**Title:** Analyzing Quantitative Data | 定量的データの分析

**Three Metric Categories:**

**1. Task Success Rate Analysis**
- Calculate: Successful tasks / Total attempts × 100
- Benchmark: >78% = Acceptable
- <50% = Critical problems

**Example Calculation:**
- 5 participants × 5 tasks = 25 attempts
- 20 successful completions
- Success Rate: 80%

**2. Time on Task Analysis**
- Average completion time
- Look for outliers
- Compare expected vs. actual
- Fast ≠ always good

**3. Error Rate Analysis**
- Slips: Unintentional mistakes
- Mistakes: Wrong actions from misunderstanding
- Recovery time
- Critical vs. minor errors

**Visual Elements:**
- Charts showing metrics
- Calculation examples
- Benchmark indicators
- Icons for each metric type

---

## Slide 5: Analyzing Qualitative Data
**Title:** Analyzing Qualitative Data | 定性的データの分析

**Three Analysis Types:**

**1. Quote Analysis**
- Direct user pain points
- Expectations vs. reality
- Confusion indicators
- Positive reactions
- Group similar quotes by theme

**2. Behavior Analysis**
- Hesitation points: Where did users pause?
- Navigation paths: Expected vs. actual route
- Repeated attempts: Multiple tries indicate confusion
- Body language: Frustration, confusion, delight

**3. SUS Score Analysis**
- Calculate individual scores (0-100)
- Average across participants
- Individual item analysis
- Identify lowest/highest agreement

**Pattern Recognition Rule:**
If 3+ participants exhibit same behavior → Pattern worth addressing

**Visual Elements:**
- Quote bubbles or callouts
- Behavior observation icons
- SUS score visualization
- Pattern identification diagram

---

## Slide 6: Finding Patterns Across Participants
**Title:** Finding Patterns Across Participants | 参加者間のパターンの発見

**Triangulation Method:**
Combine multiple data sources:
- Quantitative metrics
- Behavioral observations
- User quotes
= Complete picture

**Pattern Strength Levels:**

**Strong Patterns (High Priority)**
- 5/5 participants affected
- Causes task failure
- Consistent negative feedback
- Example: "4/5 users couldn't find price filter"

**Moderate Patterns (Medium Priority)**
- 3-4/5 participants affected
- Causes delays but eventual success
- Mixed feedback

**Weak Patterns (Low Priority)**
- 1-2/5 participants affected
- Minor impact on completion
- Individual preference vs. usability issue

**Example Pattern Analysis:**
**Issue:** Price filter not visible
**Evidence:**
- Quantitative: 40% success rate
- Behavioral: 4/5 scrolled past filter
- Quotes: "Where is the price option?" (3 users)
- Time: 4.2 min vs. expected 1.5 min

**Visual Elements:**
- Venn diagram showing triangulation
- Pattern strength indicators
- Example case study
- Evidence collection diagram

---

## Slide 7: Severity Rating Framework
**Title:** Severity Rating Framework | 重大度評価フレームワーク

**Jakob Nielsen's Severity Ratings (0-4):**

**0 = Not a Usability Problem**
- Personal preference or isolated incident
- No action needed

**1 = Cosmetic Problem**
- Fix if time allows
- Doesn't affect functionality
- Example: Minor visual inconsistency

**2 = Minor Usability Problem**
- Low priority fix
- Causes slight delay or confusion
- Example: Unclear label users eventually figure out

**3 = Major Usability Problem**
- High priority fix
- Significant delay or frustration
- Most users affected
- Example: Hidden navigation hard to discover

**4 = Usability Catastrophe**
- CRITICAL - must fix before launch
- Prevents task completion
- Affects majority of users
- Example: Broken checkout flow

**Visual Elements:**
- 0-4 scale visualization
- Color coding (green to red)
- Real-world examples for each level
- Icons indicating severity

---

## Slide 8: Prioritization Matrix
**Title:** Prioritization Matrix | 優先順位付けマトリックス

**Two-Dimensional Prioritization:**

**Frequency Axis (Horizontal):**
- High: 80-100% of users
- Medium: 40-79% of users
- Low: <40% of users

**Impact Axis (Vertical):**
- Critical: Prevents task completion
- Major: Significant delay/frustration
- Minor: Slight inconvenience

**Priority Quadrants:**

**P1 (Critical Priority)**
- High Frequency + Critical Impact
- Must fix before launch
- Example: Search function doesn't work

**P2 (High Priority)**
- High Frequency + Major Impact
- OR Medium Frequency + Critical Impact
- Fix in next iteration
- Example: Confusing navigation labels

**P3 (Medium Priority)**
- Medium Frequency + Minor Impact
- OR Low Frequency + Major Impact
- Address if time permits

**P4 (Low Priority)**
- Low Frequency + Minor Impact
- Backlog for future consideration

**Visual Elements:**
- 2×2 matrix diagram
- Color-coded quadrants
- Example issues plotted on matrix
- Priority indicators (P1-P4)

---

## Slide 9: Root Cause Analysis
**Title:** Root Cause Analysis | 根本原因分析

**The "5 Whys" Technique:**

**Example Problem:** Users can't complete checkout

**Why #1:** Why can't users complete checkout?
→ They can't find the "Confirm Purchase" button

**Why #2:** Why can't they find the button?
→ It's below the fold, not visible without scrolling

**Why #3:** Why is it below the fold?
→ Too much information above it

**Why #4:** Why is there so much information above?
→ We tried to show everything on one screen

**Why #5:** Why did we prioritize single screen?
→ Unvalidated assumption about user preference

**Root Cause Identified:**
Design decision based on unvalidated assumption

**Solution:**
- Prioritize critical actions over information density
- Test assumptions before implementing
- Consider progressive disclosure
- Make primary actions always visible

**Visual Elements:**
- Downward arrow showing "why" progression
- Root cause highlighted
- Solution box
- Symptom vs. root cause comparison

---

## Slide 10: Creating Actionable Recommendations
**Title:** Creating Actionable Recommendations | 実行可能な推奨事項の作成

**Characteristics of Good Recommendations:**

**❌ BAD:**
- "Improve navigation"
- "Make it more user-friendly"
- "Fix the issues"

**✅ GOOD:**
- "Move main menu icon to top-left corner and increase size to 44×44 px"
- "Add price filter to top of product list with clear '$' icon"
- "Display error messages in red with specific instructions"

**Required Elements:**

**1. Specific**
- Exactly what to change
- Where to change it
- How to change it

**2. Actionable**
- Clear steps to implement
- Measurable changes
- Feasible with available resources

**3. Evidence-Based**
- Reference test data
- Cite participant counts
- Include relevant quotes
- Show metrics

**4. Prioritized**
- Indicate urgency (P1-P4)
- Link to severity and frequency
- Explain importance

**5. User-Centered**
- Focus on user needs
- Not designer preferences
- Solve user problems

**Visual Elements:**
- Good vs. bad examples side by side
- Checklist of required elements
- Example recommendation
- Evidence connection diagram

---

## Slide 11: Recommendation Template
**Title:** Recommendation Template | 推奨事項テンプレート

**Structured Format:**

**Issue Title:**
Price filter is not visible to users

**Priority:** P1 (Critical)

**Evidence:**
- 4/5 participants (80%) couldn't find price filter
- Task success rate: 40% (below 78% benchmark)
- Average task time: 4.2 min (expected: 1.5 min)
- Quotes: "Where is the price option?" (P02, P03, P05)

**Root Cause:**
Filter is hidden in collapsed "Advanced Filters" section with low visibility

**Recommendations:**
1. Move price filter to prominent position at top of product listing
2. Display filter as expanded by default (not collapsed)
3. Use clear "$" icon and "Price Range" label
4. Increase filter section height from 32px to 48px

**Expected Impact:**
- Increase task success rate to >78%
- Reduce average task time to ~1.5 minutes
- Improve user satisfaction with search functionality

**Visual Elements:**
- Template structure with clear sections
- Color-coded priority indicator
- Evidence highlighted
- Impact metrics visualization

---

## Slide 12: Types of Design Improvements
**Title:** Types of Design Improvements | デザイン改善の種類

**Four Categories (Effort vs. Impact):**

**1. Quick Fixes**
- **Effort:** Low (hours/days)
- **Impact:** High
- **Examples:**
  - Label changes
  - Color/contrast adjustments
  - Button size increases
  - Error message improvements
- **Recommendation:** Prioritize these first!

**2. Interface Refinements**
- **Effort:** Medium (days/weeks)
- **Impact:** Medium-High
- **Examples:**
  - Navigation restructuring
  - Layout changes
  - Visual hierarchy improvements
  - Interaction pattern updates

**3. Feature Additions**
- **Effort:** High (weeks/months)
- **Impact:** Variable
- **Examples:**
  - New filtering options
  - Search functionality
  - User customization
  - Advanced features
- **Caution:** Only if testing shows need

**4. Fundamental Redesigns**
- **Effort:** Very High (months)
- **Impact:** Variable
- **Examples:**
  - Complete information architecture overhaul
  - Workflow redesign
  - Interaction model changes
- **Warning:** Indicates major design problems; requires new testing

**Visual Elements:**
- Effort/impact matrix
- Timeline indicators
- Examples for each category
- Priority recommendation

---

## Slide 13: Communicating Findings
**Title:** Communicating Findings | 調査結果の伝達

**Executive Summary Components:**
- Overall usability score (SUS average)
- Top 3-5 critical issues
- High-priority recommendations
- Expected impact of changes

**Visual Presentation Elements:**
- Charts and graphs (success rates, time, errors)
- Heatmaps (clicks, scrolls, attention)
- User quotes (powerful evidence)
- Video clips (actual user struggles)

**Report Structure:**
1. Executive Summary
2. Methodology
3. Participant Demographics
4. Quantitative Results
5. Qualitative Findings
6. Prioritized Issues (P1-P4)
7. Recommendations
8. Next Steps

**Audience Considerations:**
- Executives → Bottom line, ROI
- Developers → Specific fixes, technical details
- Designers → Context, user needs, design rationale

**Visual Elements:**
- Report template preview
- Stakeholder persona icons
- Communication flow diagram
- Sample findings presentation

---

## Slide 14: Iterative Design Cycle
**Title:** Iterative Design Cycle | 反復デザインサイクル

**The Continuous Improvement Loop:**

**1. Design** → Create or refine interface
**2. Test** → Evaluate with users
**3. Analyze** → Identify issues and patterns
**4. Prioritize** → Determine what to fix first
**5. Redesign** → Implement improvements
**6. Test Again** → Validate changes worked
→ **Repeat**

**Why Iteration Matters:**
- First test reveals major issues
- Second test reveals subtle issues
- Each cycle improves the design
- "Fail fast, learn fast" philosophy
- Continuous improvement is the goal

**When to Stop Testing?**
- Never! (in the real world)
- Designs evolve continuously
- User needs change
- Technology advances
- New features require testing

**For Your Projects:**
- Test once with initial prototype
- Implement high-priority fixes
- Time permitting: test again with improved version

**Visual Elements:**
- Circular process diagram
- Iteration arrows
- Before/after comparison
- Improvement trajectory graph

---

## Slide 15: Common Analysis Mistakes
**Title:** Common Analysis Mistakes to Avoid | 避けるべき一般的な分析ミス

**Six Pitfalls:**

**1. Confirmation Bias**
- **Mistake:** Only seeing data that confirms design was good
- **Avoid:** Actively look for problems; assume design has issues

**2. Cherry-Picking Data**
- **Mistake:** Highlighting positive quote while ignoring negatives
- **Avoid:** Report all findings objectively; look for patterns

**3. Ignoring Outliers**
- **Mistake:** Dismissing unusual behavior as "one weird user"
- **Avoid:** Investigate outliers - may reveal edge cases or accessibility issues

**4. Vague Recommendations**
- **Mistake:** "Make the navigation better"
- **Avoid:** Be specific with actionable steps

**5. Analysis Paralysis**
- **Mistake:** Over-analyzing forever without action
- **Avoid:** Set deadline; prioritize and move to implementation

**6. Defending Your Design**
- **Mistake:** "Users just don't understand my brilliant design"
- **Avoid:** If users don't understand, it's a design problem not user problem

**Visual Elements:**
- Warning icons for each mistake
- Good vs. bad examples
- Red X and green check marks
- "Watch out" callouts

---

## Slide 16: Activity Overview
**Title:** Your Turn: Conducting Tests and Analyzing Results
**Title (JP):** あなたの番：テストの実施と結果の分析

**Two-Part Activity (60 minutes total):**

**Part 1: Conduct Usability Tests (30 minutes)**

**What You'll Do:**
1. Test your prototype with 2-3 participants
2. Use test plan from Week 10
3. Apply think-aloud protocol
4. Record all metrics (success, time, errors, SUS)
5. Take detailed observation notes

**Moderator Reminders:**
- Stay neutral | 中立を保つ
- Prompt think-aloud | シンクアラウドを促す
- Document everything | すべてを文書化する
- Don't help or defend | 助けたり擁護したりしない

**Part 2: Analyze Results (30 minutes)**

**Analysis Steps:**
1. Calculate quantitative metrics
2. Identify patterns across participants
3. List all observed issues
4. Apply severity ratings (0-4)
5. Use priority matrix (frequency × impact)
6. Create 3-5 specific, actionable recommendations
7. Draft findings summary

**Bot Support:**
The bot will guide you through analysis templates and prioritization frameworks.

**Deliverable:**
Usability findings report with clear, actionable recommendations

**Visual Elements:**
- Two-part timeline
- Activity checklist
- Bot assistance icon
- Deliverable preview

---

## Slide 17: Bot-Conducted Assessment
**Title:** Bot-Conducted Assessment | ボット実施評価

**Assessment Format:**
- Interview-style conversation with HCI-101 Bot
- 15-20 minutes duration
- Individual assessment (no external AI allowed)

**Topics Covered:**
- Usability testing methodology
- Metrics and analysis
- Design decision rationale
- Prioritization frameworks

**What to Expect:**
- Bot will ask about your design choices
- Explain your testing process
- Justify recommendations based on evidence
- Demonstrate understanding of HCI principles

**Assessment Criteria:**
- Understanding of usability testing methods
- Ability to analyze test data
- Evidence-based reasoning
- Application of prioritization frameworks
- Clear communication of findings

**Preparation Tips:**
- Review your test results
- Be ready to explain design decisions
- Practice articulating usability issues
- Understand your prioritization rationale

**Remember:** This is conversational, not adversarial!

**Visual Elements:**
- Bot avatar or icon
- Interview/conversation graphic
- Assessment criteria checklist
- Preparation checklist

---

## Slide 18: Key Takeaways
**Title:** Key Takeaways | 重要なポイント

**Four Essential Lessons:**

**1. Analysis Transforms Data into Insights**
- Raw numbers aren't enough
- Look for patterns across participants
- Combine quantitative + qualitative data
- Triangulate to find truth

**2. Prioritization is Essential**
- Can't fix everything at once
- Use severity ratings (0-4)
- Apply frequency × impact matrix
- Focus on high-priority issues first (P1, P2)

**3. Recommendations Must Be Actionable**
- Specific, not vague
- Evidence-based, not opinion
- Prioritized by importance
- User-centered, not designer-centered

**4. Design is Iterative**
- Test → Analyze → Redesign → Test Again
- Each iteration improves the design
- Continuous improvement is the goal
- Never stop learning from users

**Next Week Preview:**
**Week 12: Accessibility and Inclusive Design**
Learn how to design interfaces that work for all users, including those with disabilities.
障害を持つユーザーを含むすべてのユーザーに機能するインターフェースをデザインする方法を学びます。

**Visual Elements:**
- Four key takeaway boxes
- Icons for each lesson
- Next week preview banner
- Motivational closing graphic

---

## PowerPoint Design Tips:

### Visual Design:
- Use consistent color scheme throughout
- Include plenty of white space
- Use large, readable fonts (min 18pt for body text)
- Add relevant icons and images
- Include bilingual text clearly separated

### Layout:
- Keep slides uncluttered
- Use bullet points effectively (max 5-7 per slide)
- Include visual breaks between sections
- Maintain consistent formatting
- Use templates for repeated elements

### Charts and Graphs:
- Make data visualizations clear and simple
- Use color coding effectively
- Label all axes and data points
- Include legends where necessary
- Ensure accessibility (colorblind-friendly palettes)

### Interactive Elements:
- Add animations for key points (but don't overdo it)
- Use transitions between slides sparingly
- Include discussion prompts
- Prepare for student questions
- Have examples ready

### Accessibility:
- Use high contrast colors
- Include alt text for images
- Ensure readable font sizes
- Consider colorblind-friendly palettes
- Test readability from back of room

### Bilingual Considerations:
- Clearly distinguish English and Japanese text
- Use consistent formatting for both languages
- Ensure both are equally readable
- Consider cultural context in examples
- Balance space allocation between languages
